{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027632,
     "end_time": "2020-12-05T21:12:05.307914",
     "exception": false,
     "start_time": "2020-12-05T21:12:05.280282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NYC Taxi Fare Prediction using CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 2.351567,
     "end_time": "2020-12-05T21:12:07.687733",
     "exception": false,
     "start_time": "2020-12-05T21:12:05.336166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import modin.pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import geopy.distance\n",
    "import time\n",
    "import ray\n",
    "start = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Ray Execution Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 21:58:42,690\tINFO services.py:1250 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "ray.init()\n",
    "env_creation_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 13.985303,
     "end_time": "2020-12-05T21:12:21.700995",
     "exception": false,
     "start_time": "2020-12-05T21:12:07.715692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "read_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dtype Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 1.459676,
     "end_time": "2020-12-05T21:12:25.731911",
     "exception": false,
     "start_time": "2020-12-05T21:12:24.272235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dtype_conversion(df):\n",
    "    df['key'] = df['key'].astype('datetime64')\n",
    "    df['fare_amount'] = df ['fare_amount'].astype('float32')\n",
    "    df['pickup_datetime'] = df['pickup_datetime'].astype('datetime64')\n",
    "    df['pickup_longitude'] = df ['pickup_longitude'].astype('float32')\n",
    "    df['pickup_latitude'] = df ['pickup_latitude'].astype('float32')\n",
    "    df['dropoff_longitude'] = df ['dropoff_longitude'].astype('float32')\n",
    "    df['dropoff_latitude'] = df ['dropoff_latitude'].astype('float32')\n",
    "    df['passenger_count'] = df ['passenger_count'].astype('uint8')\n",
    "    return df\n",
    "\n",
    "df = dtype_conversion(df)\n",
    "dtype_conversion_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Applying Constraints for NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 688.44216,
     "end_time": "2020-12-05T21:23:59.355251",
     "exception": false,
     "start_time": "2020-12-05T21:12:30.913091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: User-defined function verification is still under development in Modin. The function provided is not verified.\n"
     ]
    }
   ],
   "source": [
    "def apply_constraints(df):\n",
    "    query_frags = [\n",
    "        'fare_amount >= 2.5 and fare_amount < 500',\n",
    "        'passenger_count > 0 and passenger_count < 6',\n",
    "        'pickup_longitude > -75 and pickup_longitude < -73',\n",
    "        'dropoff_longitude > -75 and dropoff_longitude < -73',\n",
    "        'pickup_latitude > 40 and pickup_latitude < 42',\n",
    "        'dropoff_latitude > 40 and dropoff_latitude < 42'\n",
    "    ]\n",
    "    df = df.query(' and '.join(query_frags))\n",
    "    return df\n",
    "\n",
    "df = apply_constraints(df)\n",
    "apply_constraints_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engg(df):\n",
    "    df['hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['year'] = df['pickup_datetime'].dt.year\n",
    "    df['month'] = df['pickup_datetime'].dt.month\n",
    "    df['day'] = df['pickup_datetime'].dt.day\n",
    "    df['weekday'] = df['pickup_datetime'].dt.weekday\n",
    "\n",
    "    def jfk_dist(trip):\n",
    "        jfk_lat = 40.6413\n",
    "        jfk_long = -73.7781\n",
    "        dropoff_lat = trip['dropoff_latitude']\n",
    "        dropoff_long = trip['dropoff_longitude']\n",
    "        jfk_distance = geopy.distance.geodesic((dropoff_lat, dropoff_long), (jfk_lat, jfk_long)).miles\n",
    "        return jfk_distance\n",
    "\n",
    "    def lga_dist(trip):\n",
    "        lga_lat = 40.7769\n",
    "        lga_long = -73.8740\n",
    "        dropoff_lat = trip['dropoff_latitude']\n",
    "        dropoff_long = trip['dropoff_longitude']\n",
    "        lga_distance = geopy.distance.geodesic((dropoff_lat, dropoff_long), (lga_lat, lga_long)).miles\n",
    "        return lga_distance\n",
    "\n",
    "    def ewr_dist(trip):\n",
    "        ewr_lat = 40.6895\n",
    "        ewr_long = -74.1745\n",
    "        dropoff_lat = trip['dropoff_latitude']\n",
    "        dropoff_long = trip['dropoff_longitude']\n",
    "        ewr_distance = geopy.distance.geodesic((dropoff_lat, dropoff_long), (ewr_lat, ewr_long)).miles\n",
    "        return ewr_distance\n",
    "\n",
    "    def tsq_dist(trip):\n",
    "        tsq_lat = 40.7580\n",
    "        tsq_long = -73.9855\n",
    "        dropoff_lat = trip['dropoff_latitude']\n",
    "        dropoff_long = trip['dropoff_longitude']\n",
    "        tsq_distance = geopy.distance.geodesic((dropoff_lat, dropoff_long), (tsq_lat, tsq_long)).miles\n",
    "        return tsq_distance\n",
    "\n",
    "    def met_dist(trip):\n",
    "        met_lat = 40.7794\n",
    "        met_long = -73.9632\n",
    "        dropoff_lat = trip['dropoff_latitude']\n",
    "        dropoff_long = trip['dropoff_longitude']\n",
    "        met_distance = geopy.distance.geodesic((dropoff_lat, dropoff_long), (met_lat, met_long)).miles\n",
    "        return met_distance\n",
    "\n",
    "    def wtc_dist(trip):\n",
    "        wtc_lat = 40.7126\n",
    "        wtc_long = -74.0099\n",
    "        dropoff_lat = trip['dropoff_latitude']\n",
    "        dropoff_long = trip['dropoff_longitude']\n",
    "        wtc_distance = geopy.distance.geodesic((dropoff_lat, dropoff_long), (wtc_lat, wtc_long)).miles\n",
    "        return wtc_distance\n",
    "\n",
    "    def calc_dists(df):\n",
    "        df['jfk'] = df.apply(lambda x: jfk_dist(x), axis = 1 )\n",
    "        df['lga'] = df.apply(lambda x: lga_dist(x), axis = 1 )\n",
    "        df['ewr'] = df.apply(lambda x: ewr_dist(x), axis = 1 )\n",
    "        df['tsq'] = df.apply(lambda x: tsq_dist(x), axis = 1 )\n",
    "        df['met'] = df.apply(lambda x: met_dist(x), axis = 1 )\n",
    "        df['wtc'] = df.apply(lambda x: wtc_dist(x), axis = 1 )\n",
    "        return df\n",
    "\n",
    "    df = calc_dists(df)\n",
    "    df = df.drop(['pickup_datetime','key'], axis=1)\n",
    "    return df\n",
    "\n",
    "df = feature_engg(df)\n",
    "feature_engg_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop('fare_amount', axis = 1), df['fare_amount']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "split_data_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(apply_func pid=1510486)\u001b[0m \n",
      "[0]\ttrain-rmse:13.91973\tvalid-rmse:13.92266\n",
      "[100]\ttrain-rmse:4.38640\tvalid-rmse:4.43147\n",
      "[200]\ttrain-rmse:4.11563\tvalid-rmse:4.16624\n",
      "[300]\ttrain-rmse:3.99647\tvalid-rmse:4.04973\n",
      "[400]\ttrain-rmse:3.93042\tvalid-rmse:3.98586\n",
      "[500]\ttrain-rmse:3.88584\tvalid-rmse:3.94280\n",
      "[600]\ttrain-rmse:3.85965\tvalid-rmse:3.91793\n",
      "[700]\ttrain-rmse:3.84029\tvalid-rmse:3.89994\n",
      "[800]\ttrain-rmse:3.82041\tvalid-rmse:3.88115\n",
      "[900]\ttrain-rmse:3.80722\tvalid-rmse:3.86908\n",
      "[999]\ttrain-rmse:3.79582\tvalid-rmse:3.85911\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_test, label=y_test)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_params = {\n",
    "    'min_child_weight': 1, \n",
    "    'learning_rate': 0.05, \n",
    "    'colsample_bytree': 0.7, \n",
    "    'subsample': 0.7,\n",
    "    'booster' : 'gbtree',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_jobs' : -1,\n",
    "    'eval_metric': 'rmse'}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, 1000, watchlist, early_stopping_rounds=100, verbose_eval=100)\n",
    "training_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error :  3.8050902\n",
      "Mean Absolute Error :  1.7102177\n",
      "R-squared Score :  0.8453670447259642\n"
     ]
    }
   ],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return (rmse, mae, r2)\n",
    "\n",
    "def test(model):\n",
    "    df = pd.read_csv('../data/test.csv')\n",
    "    df = dtype_conversion(df)\n",
    "    df = apply_constraints(df)\n",
    "    df = feature_engg(df)\n",
    "    df, actual = df.drop('fare_amount', axis = 1), df['fare_amount']\n",
    "    df = xgb.DMatrix(df)\n",
    "\n",
    "    pred = model.predict(df)\n",
    "    rmse, mae, r2 = eval_metrics(actual, pred)\n",
    "    print(\"Root Mean Squared Error : \", rmse)\n",
    "    print(\"Mean Absolute Error : \", mae)\n",
    "    print(\"R-squared Score : \", r2)\n",
    "\n",
    "test(model)\n",
    "test_time = time.perf_counter()\n",
    "stop = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Time Taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Execution Environment :  2.429901456926018s\n",
      "Reading :  13.60694275307469s\n",
      "Data Type Conversion :  0.42991262290161103s\n",
      "Applying Constraints :  265.9359644301003s\n",
      "Feature Engineering :  2613.31897444895s\n",
      "Splitting Data :  2613.31897444895s\n",
      "Training :  16987.63809621299s\n",
      "Testing :  329.0208089299267s\n",
      "Total :  20572.9191167939s\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Execution Environment : \", env_creation_time - start, \"s\")\n",
    "print(\"Reading : \", read_time - env_creation_time, \"s\")\n",
    "print(\"Data Type Conversion : \", dtype_conversion_time - read_time, \"s\")\n",
    "print(\"Applying Constraints : \", apply_constraints_time - dtype_conversion_time, \"s\")\n",
    "print(\"Feature Engineering : \", feature_engg_time - apply_constraints_time, \"s\")\n",
    "print(\"Splitting Data : \", split_data_time - feature_engg_time, \"s\")\n",
    "print(\"Training : \", training_time - split_data_time, \"s\")\n",
    "print(\"Testing : \", test_time - training_time, \"s\")\n",
    "print(\"Total : \", stop - start, \"s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "papermill": {
   "duration": 31636.595024,
   "end_time": "2020-12-06T05:59:16.690829",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-05T21:12:00.095805",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
